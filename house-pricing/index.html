<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  

  
  
  
  
  
  

  

  
  
  
    
  
  <meta name="description" content="">

  
  <link rel="alternate" hreflang="en-us" href="https://paulobreviglieri.com/house-pricing/">

  


  
  
  
  <meta name="theme-color" content="#000080">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/atom-one-light.min.css" crossorigin="anonymous" title="hl-light">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/atom-one-light.min.css" crossorigin="anonymous" title="hl-dark" disabled>
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Oxygen:300light,400,700bold%7COxygen+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-165357798-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-165357798-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hue0b5dbdcd29e15f3bb2c3e480ec18a0b_14701_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hue0b5dbdcd29e15f3bb2c3e480ec18a0b_14701_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://paulobreviglieri.com/house-pricing/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@pcbreviglieri">
  <meta property="twitter:creator" content="@pcbreviglieri">
  
  <meta property="og:site_name" content="Paulo Breviglieri • Data Science &amp; Machine Learning">
  <meta property="og:url" content="https://paulobreviglieri.com/house-pricing/">
  <meta property="og:title" content="Advanced Regressions Enabling Enhanced House Price Predictions | Paulo Breviglieri • Data Science &amp; Machine Learning">
  <meta property="og:description" content=""><meta property="og:image" content="https://paulobreviglieri.com/images/logo.svg">
  <meta property="twitter:image" content="https://paulobreviglieri.com/images/logo.svg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-01-01T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-01-01T00:00:00&#43;00:00">
  

  



  


  


  





  <title>Advanced Regressions Enabling Enhanced House Price Predictions | Paulo Breviglieri • Data Science &amp; Machine Learning</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" class=" ">

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  











  


<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/"><img src="/images/logo.svg" alt="Paulo Breviglieri • Data Science &amp; Machine Learning"></a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/"><img src="/images/logo.svg" alt="Paulo Breviglieri • Data Science &amp; Machine Learning"></a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/portfolio"><span>Portfolio</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/about"><span>About</span></a>
        </li>

        
        

        

        
        
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/" data-target="[]"><span></span></a>
        </li>

        
        

      

        

        
        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link" href="https://linkedin.com/in/pcbreviglieri" target="_blank" rel="noopener"><span><i class="fab fa-linkedin-in" style="font-size: 1rem; line-height: 1; color: #0E76A8"></i></span></a>
        </li>

        

        
        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link" href="https://kaggle.com/pcbreviglieri" target="_blank" rel="noopener"><span><i class="fab fa-kaggle" style="font-size: 0.85rem; line-height: 1; color: #20BEFF"></i></span></a>
        </li>

        

        
        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link" href="https://github.com/pcbreviglieri" target="_blank" rel="noopener"><span><i class="fab fa-github" style="font-size: 1rem; line-height: 1; color: #333333"></i></span></a>
        </li>

        

        
        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link" href="https://gitlab.com/pcbreviglieri" target="_blank" rel="noopener"><span><i class="fab fa-gitlab" style="font-size: 1rem; line-height: 1; color: #E2432A"></i></span></a>
        </li>

        

        
        
        

        <li class="nav-item">
          <a class="nav-link" href="/"><span><i class="far fa-envelope" style="font-size: 1rem; line-height: 1; color: #209050"></i></span></a>
        </li>

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      

      

    </ul>

  </div>
</nav>



  
<span class="js-widget-page d-none"></span>





  
  
  
  




  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-01-introduction" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1 style="text-align: center; font-size: 30px; color: #ff3000;">Advanced Regressions Enabling Enhanced House Price Predictions</h1>
<p>April 29, 2020 - By Paulo Breviglieri</p>
<h1>1. Introduction</h1>
<p>This machine learning regression exercise was inspired by Kaggle's "Housing Prices Competition for Kaggle Learn Users". Based on the <a href="http://jse.amstat.org/v19n3/decock.pdf" target="_blank">Ames Housing dataset</a>, compiled by Dean De Cock (Truman State University) in 2011 for use in general data science education, the competition requests predictions of sale prices for a set of residential properties in Ames, Iowa.</p>
<p>The original dataset comprises 2930 observations, for which 79 explanatory variables (the independent variables) and sale prices (the dependent variable) are known and supplied. In the competition, Kaggle furnished optimized train and test subsets of the original Ames Housing dataset with 1460 and 1459 observations, respectively. Sale prices are disclosed for the training set and must be predicted for the test set. Submissions are ranked based on the Mean Absolute Error (MAE) derived from predicted and actual sale prices for the 1459 observations in the test set.</p>
<p>This exercise covers all steps of a typical regression program, including an initial setup, data preprocessing, machine learning (advanced regression) and result analysis. Code is supplied also for the submission of predictions to Kaggle's competition.</p>
<p>Logic enhancement and code forking are welcome and encouraged provided that proper referencing to this work is made. Latest code version may be found in the author's <a href="https://github.com/pcbreviglieri" target="_blank">GitHub</a> repository. Thank you.</p>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-02-initial-setup" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>2. Initial setup</h1>
<h2>2.1. Importing required libraries</h2>
<p>Along with traditional libraries imported for tensor manipulation, mathematical operations and graphics development, specific machine learning modules are used in this exercise: regressors (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html" target="_blank">ElasticNet</a>, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html" target="_blank">LassoCV</a>, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html" target="_blank">RidgeCV</a>, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html" target="_blank">GradientBoostingRegressor</a>, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html" target="_blank">SVR</a>, <a href="https://xgboost.readthedocs.io/en/latest/#" target="_blank">XGBoost</a>, <a href="http://rasbt.github.io/mlxtend/user_guide/regressor/StackingCVRegressor/" target="_blank">StackingCVRegressor</a>), cross validation engines, a scaler and metrics methods. Comments on the choice of regressors are provided in Section 4.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns
<span style="color:#f92672">from</span> datetime <span style="color:#f92672">import</span> datetime

<span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> skew
<span style="color:#f92672">from</span> scipy.special <span style="color:#f92672">import</span> boxcox1p
<span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> boxcox_normmax

<span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> ElasticNetCV, LassoCV, RidgeCV
<span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> GradientBoostingRegressor
<span style="color:#f92672">from</span> sklearn.svm <span style="color:#f92672">import</span> SVR
<span style="color:#f92672">from</span> sklearn.pipeline <span style="color:#f92672">import</span> make_pipeline
<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> RobustScaler
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> KFold, cross_val_score
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_squared_error, mean_squared_log_error, mean_absolute_error
<span style="color:#f92672">from</span> mlxtend.regressor <span style="color:#f92672">import</span> StackingCVRegressor
<span style="color:#f92672">from</span> xgboost <span style="color:#f92672">import</span> XGBRegressor

<span style="color:#f92672">import</span> warnings
</code></pre></div></div>
<h2>2.2. Customized functions</h2>
<p>Functions were developed to assist with graphical analysis of specific dataset elements (features or observations) and with cross-validation scoring of regression strategies. Please refer to the respective docstrings below for details. Note that all function variable names, by coding principle, start with the "f_" string, allowing for containerized processing within the function execution environment, not affecting global variables.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">assessment</span>(f_data, f_y_feature, f_x_feature, f_index<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Develops and displays a histogram and a scatter plot for a dependent / independent variable pair from
</span><span style="color:#e6db74">    a dataframe and, optionally, highlights a specific observation on the plot in a different color (red).
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    Also optionally, if an independent feature is not informed, the scatterplot is not displayed.
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    Keyword arguments:
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    f_data      Tensor containing the dependent / independent variable pair.
</span><span style="color:#e6db74">                Pandas dataframe
</span><span style="color:#e6db74">    f_y_feature Dependent variable designation.
</span><span style="color:#e6db74">                String
</span><span style="color:#e6db74">    f_x_feature Independent variable designation.
</span><span style="color:#e6db74">                String
</span><span style="color:#e6db74">    f_index     If greater or equal to zero, the observation denoted by f_index will be plotted in red.
</span><span style="color:#e6db74">                Integer
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">for</span> f_row <span style="color:#f92672">in</span> f_data:
        <span style="color:#66d9ef">if</span> f_index <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>:
            f_color <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(f_data[f_row]<span style="color:#f92672">.</span>index <span style="color:#f92672">==</span> f_index,<span style="color:#e6db74">&#39;r&#39;</span>,<span style="color:#e6db74">&#39;g&#39;</span>)
            f_hue <span style="color:#f92672">=</span> None
        <span style="color:#66d9ef">else</span>:
            f_color <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;b&#39;</span>
            f_hue <span style="color:#f92672">=</span> None
    
    f_fig, f_a <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>,<span style="color:#ae81ff">4</span>))
    
    f_chart1 <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>distplot(f_data[f_x_feature], ax<span style="color:#f92672">=</span>f_a[<span style="color:#ae81ff">0</span>], kde<span style="color:#f92672">=</span>False, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;r&#39;</span>)
    f_chart1<span style="color:#f92672">.</span>set_xlabel(f_x_feature,fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
    
    <span style="color:#66d9ef">if</span> f_index <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span>:
        f_chart2 <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>scatter(f_data[f_x_feature], f_data[f_y_feature], c<span style="color:#f92672">=</span>f_color, edgecolors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;w&#39;</span>)
        f_chart2 <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>xlabel(f_x_feature, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
        f_chart2 <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>ylabel(f_y_feature, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
    <span style="color:#66d9ef">else</span>:
        f_chart2 <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>scatterplot(x<span style="color:#f92672">=</span>f_x_feature, y<span style="color:#f92672">=</span>f_y_feature, data<span style="color:#f92672">=</span>f_data, hue<span style="color:#f92672">=</span>f_hue, legend<span style="color:#f92672">=</span>False)
        f_chart2<span style="color:#f92672">.</span>set_xlabel(f_x_feature,fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
        f_chart2<span style="color:#f92672">.</span>set_ylabel(f_y_feature,fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)

    plt<span style="color:#f92672">.</span>show()


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">correlation_map</span>(f_data, f_feature, f_number):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Develops and displays a heatmap plot referenced to a primary feature of a dataframe, highlighting
</span><span style="color:#e6db74">    the correlation among the &#39;n&#39; mostly correlated features of the dataframe.
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    Keyword arguments:
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    f_data      Tensor containing all relevant features, including the primary.
</span><span style="color:#e6db74">                Pandas dataframe
</span><span style="color:#e6db74">    f_feature   The primary feature.
</span><span style="color:#e6db74">                String
</span><span style="color:#e6db74">    f_number    The number of features most correlated to the primary feature.
</span><span style="color:#e6db74">                Integer
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    f_most_correlated <span style="color:#f92672">=</span> f_data<span style="color:#f92672">.</span>corr()<span style="color:#f92672">.</span>nlargest(f_number,f_feature)[f_feature]<span style="color:#f92672">.</span>index
    f_correlation <span style="color:#f92672">=</span> f_data[f_most_correlated]<span style="color:#f92672">.</span>corr()
    
    f_mask <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros_like(f_correlation)
    f_mask[np<span style="color:#f92672">.</span>triu_indices_from(f_mask)] <span style="color:#f92672">=</span> True
    <span style="color:#66d9ef">with</span> sns<span style="color:#f92672">.</span>axes_style(<span style="color:#e6db74">&#34;white&#34;</span>):
        f_fig, f_ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">10</span>))
        f_ax <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>heatmap(f_correlation, mask<span style="color:#f92672">=</span>f_mask, vmin<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, vmax<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, square<span style="color:#f92672">=</span>True,
                           annot<span style="color:#f92672">=</span>True, annot_kws<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;size&#34;</span>: <span style="color:#ae81ff">10</span>}, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;BuPu&#34;</span>)

    plt<span style="color:#f92672">.</span>show()
    
    
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">xval_rmse_scoring</span>(f_model, f_X, f_y, f_cv):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Returns a machine learning model cross-validated score based on the Root Mean Squared Error (RMSE) metric.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    Keyword arguments:
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    f_model     Machine learning model.
</span><span style="color:#e6db74">                Object instance
</span><span style="color:#e6db74">    f_X_        Tensor containing features for modeling.
</span><span style="color:#e6db74">                Pandas dataframe
</span><span style="color:#e6db74">    f_y         Tensor containing targets for modeling.
</span><span style="color:#e6db74">                Pandas series
</span><span style="color:#e6db74">    f_cv        Cross-validation splitting strategy.
</span><span style="color:#e6db74">                Please refer to scikit-learn&#39;s model_selection cross_val_score for further information.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sqrt(<span style="color:#f92672">-</span>cross_val_score(f_model, f_X, f_y,
                                    scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;neg_mean_squared_error&#39;</span>,
                                    cv<span style="color:#f92672">=</span>f_cv))
</code></pre></div></div>
<h2>2.3. Importing required datasets into dataframes</h2>
<p>Variables starting with numbers are renamed properly for further calling as dataframe elements. The original 'Id' feature is dropped and incorporated as index for observations.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">warnings<span style="color:#f92672">.</span>filterwarnings(<span style="color:#e6db74">&#39;ignore&#39;</span>)
sns<span style="color:#f92672">.</span>set()
start_time <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()

train <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;train.csv&#39;</span>)
test <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;test.csv&#39;</span>)

train<span style="color:#f92672">.</span>rename(columns<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;1stFlrSF&#34;</span>: <span style="color:#e6db74">&#34;FstFlSF&#34;</span>, <span style="color:#e6db74">&#34;2ndFlrSF&#34;</span>: <span style="color:#e6db74">&#34;SecFlSF&#34;</span>, <span style="color:#e6db74">&#34;3SsnPorch&#34;</span>: <span style="color:#e6db74">&#34;ThreeSPorch&#34;</span>}, inplace<span style="color:#f92672">=</span>True)
test<span style="color:#f92672">.</span>rename(columns<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;1stFlrSF&#34;</span>: <span style="color:#e6db74">&#34;FstFlSF&#34;</span>, <span style="color:#e6db74">&#34;2ndFlrSF&#34;</span>: <span style="color:#e6db74">&#34;SecFlSF&#34;</span>, <span style="color:#e6db74">&#34;3SsnPorch&#34;</span>: <span style="color:#e6db74">&#34;ThreeSPorch&#34;</span>}, inplace<span style="color:#f92672">=</span>True)

train<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;Id&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, inplace<span style="color:#f92672">=</span>True)
test<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;Id&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, inplace<span style="color:#f92672">=</span>True)

train_features <span style="color:#f92672">=</span> train<span style="color:#f92672">.</span>iloc[:, :<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
train_targets <span style="color:#f92672">=</span> train<span style="color:#f92672">.</span>iloc[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
test_features <span style="color:#f92672">=</span> test
</code></pre></div></div>
<h2>2.4. Redefinition of specific feature types (numerical vs categorical)</h2>
<p>Specific numerical features ('MSSubClass', 'MoSold' and 'YrSold') have a discrete nature. Transforming their numerical values into strings enables further treatment as categorical features along the code.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_features[<span style="color:#e6db74">&#39;MSSubClass&#39;</span>] <span style="color:#f92672">=</span> train_features[<span style="color:#e6db74">&#39;MSSubClass&#39;</span>]<span style="color:#f92672">.</span>astype(str)
train_features[<span style="color:#e6db74">&#39;MoSold&#39;</span>] <span style="color:#f92672">=</span> train_features[<span style="color:#e6db74">&#39;MoSold&#39;</span>]<span style="color:#f92672">.</span>astype(str)
train_features[<span style="color:#e6db74">&#39;YrSold&#39;</span>] <span style="color:#f92672">=</span> train_features[<span style="color:#e6db74">&#39;YrSold&#39;</span>]<span style="color:#f92672">.</span>astype(str)
test_features[<span style="color:#e6db74">&#39;MSSubClass&#39;</span>] <span style="color:#f92672">=</span> test_features[<span style="color:#e6db74">&#39;MSSubClass&#39;</span>]<span style="color:#f92672">.</span>astype(str)
test_features[<span style="color:#e6db74">&#39;MoSold&#39;</span>] <span style="color:#f92672">=</span> test_features[<span style="color:#e6db74">&#39;MoSold&#39;</span>]<span style="color:#f92672">.</span>astype(str)
test_features[<span style="color:#e6db74">&#39;YrSold&#39;</span>] <span style="color:#f92672">=</span> test_features[<span style="color:#e6db74">&#39;YrSold&#39;</span>]<span style="color:#f92672">.</span>astype(str)
</code></pre></div></div>
<h2>2.5. Segregation of numerical and categorical features</h2>
<p>Numerical and categorical features are identified and segregated into two speficic lists. Later, the whole train and test dataframes have their features reordered (numerical followed by categorical).</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">features_numerical <span style="color:#f92672">=</span> []
features_categorical <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> column <span style="color:#f92672">in</span> train_features<span style="color:#f92672">.</span>columns:
    <span style="color:#66d9ef">if</span> train_features[column]<span style="color:#f92672">.</span>dtype <span style="color:#f92672">in</span> [<span style="color:#e6db74">&#39;int16&#39;</span>, <span style="color:#e6db74">&#39;int32&#39;</span>, <span style="color:#e6db74">&#39;int64&#39;</span>, <span style="color:#e6db74">&#39;float16&#39;</span>, <span style="color:#e6db74">&#39;float32&#39;</span>, <span style="color:#e6db74">&#39;float64&#39;</span>]:
        features_numerical<span style="color:#f92672">.</span>append(column)
    <span style="color:#66d9ef">elif</span> train_features[column]<span style="color:#f92672">.</span>dtype <span style="color:#f92672">==</span> object:
        features_categorical<span style="color:#f92672">.</span>append(column)

new_order <span style="color:#f92672">=</span> features_numerical <span style="color:#f92672">+</span> features_categorical
train_features <span style="color:#f92672">=</span> train_features[new_order]
test_features <span style="color:#f92672">=</span> test_features[new_order]
</code></pre></div></div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-03-preprocessing" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>3. Preprocessing</h1>
<h2>3.1. Initial inspection</h2>
<p>The primary aspects of the problem at hand - the sale of a residential property - must remain in sight throughout the development of the data science exercise. In this case, we must permanently keep in mind the major attributes considered by a buyer when looking for a house: land area, built area, number of units (rooms, bathrooms, kitchen etc.), overall property quality and age.</p>
<p>The train and test dataset csv files have first been imported into Excel <a href="https://github.com/pcbreviglieri/data-science-enhanced-house-price-predictions/tree/master/support" target="_blank">(here)</a> for an initial evaluation. Features of similar nature were grouped together enabling a more focused analysis of the key aspects aforementioned:</p>
<ul>
    <li>Geography: MSZoning, Neighborhood, Condition1, Condition2</li>
    <li>Land: LotFrontage, LotArea, LotShape, LotConfig, LandContour, LandSlope, Street, Alley, Fence</li>
    <li>Age: YearBuilt, YearRemodAdd</li>
    <li>Building: BldgType, MSSubClass, HouseStyle</li>
    <li>Quality: Functional, OverallQual, OverallCond, ExterQual, ExterCond, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, HeatingQC, KitchenQual, FireplaceQu, GarageQual, GarageCOnd, PoolQC</li>
    <li>Area: BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea</li>
    <li>Structure and Masonry: Foundation, MsnVnrType, MsnVnrArea</li>
    <li>Experior: RoofStyle, RoofMatl, Exterior1st, Exterior2nd</li>
    <li>Utilities: Utilities, Heating, CentraiAir, Electrical</li>
    <li>Living Units: TotRmsAbvGrd, BedroomAbvGrd, KitchenAbvGr, Fireplaces</li>
    <li>Bathrooms: BsmtFullBath, BsmtHalfBath, FullBath, HalfBath</li>
    <li>Garage: GarageType, GarageYrBlt, GarageFinish, GarageCars, PavedDrive</li>
    <li>Miscelaneous: MiscFeature, MiscVal</li>
    <li>Sales: MoSold, YrSold, SaleType, SaleCondition</li>
</ul>
<h2>3.2. Concatenating train and test features</h2>
<p>As features may be transformed, deleted or created along the data preprocessing phase, stacking train and test set features on top of each other facilitates such operations. Note that the training targets have been previously segregated in the 'train_targets' series, are not included in 'train_test_features' and therefore will not be manipulated at this point.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_test_features <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([train_features, test_features], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</code></pre></div></div>
<h2>3.3. Numerical features</h2>
<h3>3.3.1. Missing values</h3>
<p>Numerical features with missing values are identified. Their names are included in a specific list and displayed.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">missing_numerical <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> feature <span style="color:#f92672">in</span> features_numerical:
    <span style="color:#66d9ef">if</span> train_test_features<span style="color:#f92672">.</span>count()[feature] <span style="color:#f92672">&lt;</span> train_test_features<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]:
        missing_numerical<span style="color:#f92672">.</span>append(feature)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Numerical features with missing values before treatment: {len(missing_numerical)}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
<span style="color:#66d9ef">print</span>(missing_numerical)
</code></pre></div></div>
<p class="codeoutput">Numerical features with missing values before treatment: 11<br />
['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageArea']</p>
<p>Replacement strategy:</p>
<ol>
    <li>LotFrontage - Nulls replaced with the median of lot frontage values of properties in the same neighborhood, as those may be framed by the local zoning regulation.</li>
    <li>MasVnrArea - Inspection shows that nulls occur for cases where MasVnrType is also null. Replaced with zeros.</li>
    <li>BsmtFinSF1, BsmtFinSF2, BsmtUnfSF and TotalBsmtSF - Nulls correpond to cases where the property does not have a basement. Replaced with zeros.</li>
    <li>BsmtFullBath, BsmtHalfBath - Nulls correpond to cases where the property does not have a basement (see item 3 above). Replaced with zeros.</li>
    <li>GarageYrBlt, GarageArea, GarageCars - Nulls correpond to cases where the property does not have a garage. Replaced with zeros.</li>
</ol>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_test_features[<span style="color:#e6db74">&#39;LotFrontage&#39;</span>] <span style="color:#f92672">=</span> train_test_features<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;Neighborhood&#39;</span>)[<span style="color:#e6db74">&#39;LotFrontage&#39;</span>]<span style="color:#f92672">.</span>transform(<span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">.</span>fillna(x<span style="color:#f92672">.</span>median()))
train_test_features[<span style="color:#e6db74">&#39;MasVnrArea&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;MasVnrArea&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtFinSF1&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtFinSF1&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtFinSF2&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtFinSF2&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtUnfSF&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtUnfSF&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
train_test_features[<span style="color:#e6db74">&#39;TotalBsmtSF&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;TotalBsmtSF&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtFullBath&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtFullBath&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtHalfBath&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtHalfBath&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
train_test_features[<span style="color:#e6db74">&#39;GarageYrBlt&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;GarageYrBlt&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
train_test_features[<span style="color:#e6db74">&#39;GarageArea&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;GarageArea&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
train_test_features[<span style="color:#e6db74">&#39;GarageCars&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;GarageCars&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)

missing_numerical<span style="color:#f92672">.</span>clear()
<span style="color:#66d9ef">for</span> feature <span style="color:#f92672">in</span> features_numerical:
    <span style="color:#66d9ef">if</span> train_test_features<span style="color:#f92672">.</span>count()[feature] <span style="color:#f92672">&lt;</span> train_test_features<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]:
        missing_numerical<span style="color:#f92672">.</span>append(feature)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Numerical features with missing values after treatment: {len(missing_numerical)}&#39;</span>)
</code></pre></div></div>
<p class="codeoutput">Numerical features with missing values after treatment: 0</p>
<h3>3.3.2. Creation of new features from numerical features</h3>
<p>Whenever possible, additional features related to key aspects of the problem under analysis may be created to reinforce the weight of such aspects in the regression. In the current case (real estate pricing), features associated with land area, built area, number of rooms, overall property quality and age are of supreme relevance.</p>
<p>In this sense, the following additional features are proposed:</p>
<ul>
    <li>Time elapsed since property was originally built (measured at sales year);</li>
    <li>Time elapsed since property was last remodelled (also measured at sales year);</li>
    <li>Total walled area, total porch area and total occupied area (the sum of walled and porch areas);</li>
    <li>Other rooms, equaling the number of total rooms excluding bedroom(s) and kitchen(s);</li>
    <li>Total bathrooms, with different weights for full (1.0) and half (0.5) bathrooms;</li>
    <li>Average lot depth, derived from lot area and lot frontage (rectangular lot shape assumed).</li>
</ul>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_test_features[<span style="color:#e6db74">&#39;YearsSinceBuilt&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;YrSold&#39;</span>]<span style="color:#f92672">.</span>astype(int) <span style="color:#f92672">-</span> train_test_features[<span style="color:#e6db74">&#39;YearBuilt&#39;</span>]
train_test_features[<span style="color:#e6db74">&#39;YearsSinceRemod&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;YrSold&#39;</span>]<span style="color:#f92672">.</span>astype(int) <span style="color:#f92672">-</span> train_test_features[<span style="color:#e6db74">&#39;YearRemodAdd&#39;</span>]

train_test_features[<span style="color:#e6db74">&#39;TotalWalledArea&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;TotalBsmtSF&#39;</span>] <span style="color:#f92672">+</span> train_test_features[<span style="color:#e6db74">&#39;GrLivArea&#39;</span>]
train_test_features[<span style="color:#e6db74">&#39;TotalPorchArea&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;OpenPorchSF&#39;</span>] <span style="color:#f92672">+</span> train_test_features[<span style="color:#e6db74">&#39;ThreeSPorch&#39;</span>] <span style="color:#f92672">+</span> train_test_features[<span style="color:#e6db74">&#39;EnclosedPorch&#39;</span>] <span style="color:#f92672">+</span> train_test_features[<span style="color:#e6db74">&#39;ScreenPorch&#39;</span>] <span style="color:#f92672">+</span> train_test_features[<span style="color:#e6db74">&#39;WoodDeckSF&#39;</span>]
train_test_features[<span style="color:#e6db74">&#39;TotalOccupiedArea&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;TotalWalledArea&#39;</span>] <span style="color:#f92672">+</span> train_test_features[<span style="color:#e6db74">&#39;TotalPorchArea&#39;</span>]

train_test_features[<span style="color:#e6db74">&#39;OtherRooms&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;TotRmsAbvGrd&#39;</span>] <span style="color:#f92672">-</span> train_test_features[<span style="color:#e6db74">&#39;BedroomAbvGr&#39;</span>] <span style="color:#f92672">-</span> train_test_features[<span style="color:#e6db74">&#39;KitchenAbvGr&#39;</span>]
train_test_features[<span style="color:#e6db74">&#39;TotalBathrooms&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;FullBath&#39;</span>] <span style="color:#f92672">+</span> (<span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> train_test_features[<span style="color:#e6db74">&#39;HalfBath&#39;</span>]) <span style="color:#f92672">+</span> train_test_features[<span style="color:#e6db74">&#39;BsmtFullBath&#39;</span>] <span style="color:#f92672">+</span> (<span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> train_test_features[<span style="color:#e6db74">&#39;BsmtHalfBath&#39;</span>])

train_test_features[<span style="color:#e6db74">&#39;LotDepth&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;LotArea&#39;</span>] <span style="color:#f92672">/</span> train_test_features[<span style="color:#e6db74">&#39;LotFrontage&#39;</span>]
</code></pre></div></div>
<h3>3.3.3. Feature profiling</h3>
<p>Skewness may be interpreted as the extent to which a variable distribution differs from a normal distribution. Skewed variables (features) must be identified and normalized during preprocessing. Usually a variable (feature) is considered 'skewed' when its skew factor exceeds 0.5. Identification is performed with the help of scipy's methods 'skew', 'boxcox1p' and 'boxcox_normmax'.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">skew_values <span style="color:#f92672">=</span> train_test_features[features_numerical]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: skew(x))
high_skew <span style="color:#f92672">=</span> skew_values[skew_values <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.5</span>]
skew_indices <span style="color:#f92672">=</span> high_skew<span style="color:#f92672">.</span>index
</code></pre></div></div>
<p>Visualization of distribution and correlation with the dependent variable BEFORE normalization (only 3 sample skewed variables displayed with pictures):</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">for</span> index <span style="color:#f92672">in</span> skew_indices:
    assessment(pd<span style="color:#f92672">.</span>concat([train_test_features<span style="color:#f92672">.</span>iloc[:len(train_targets), :], train_targets], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>), <span style="color:#e6db74">&#39;SalePrice&#39;</span>, index, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</code></pre></div></div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/before-01.png' alt='LotFrontage before normalization'>
</div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/before-02.png' alt='LotArea before normalization'>
</div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/before-12.png' alt='GrLivArea before normalization'>
</div>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">for</span> index <span style="color:#f92672">in</span> skew_indices:
    train_test_features[index] <span style="color:#f92672">=</span> boxcox1p(train_test_features[index], boxcox_normmax(train_test_features[index] <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>))
</code></pre></div></div>
<p>Visualization of distribution and correlation with the dependent variable AFTER normalization</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">for</span> index <span style="color:#f92672">in</span> skew_indices:
    assessment(pd<span style="color:#f92672">.</span>concat([train_test_features<span style="color:#f92672">.</span>iloc[:len(train_targets), :], train_targets], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>), <span style="color:#e6db74">&#39;SalePrice&#39;</span>, index, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</code></pre></div></div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/after-01.png' alt='LotFrontage after normalization'>
</div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/after-02.png' alt='LotArea after normalization'>
</div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/after-12.png' alt='GrLivArea after normalization'>
</div>
<p>It is important to mention that in specific cases a skewed pattern remains even after normalization.</p>
<h3>3.3.4. Identifying and dropping numerical features with predominant values</h3>
<p>Specific numerical features with one predominant value across all observations are barely correlated to the dependent value (sales prices) and therefore their prediction value is irrelevant. The accumulation of features with predominant values (zeros or ones in particular) may lead to sparse datasets and deteriorated regressions.</p>
<p>Numerical features with one predominant value present in more than 99.5% of all observations (train and test sets combined) are identified and dropped. </p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">numerical_features_to_be_dropped <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> feature <span style="color:#f92672">in</span> features_numerical:
    predominant_value_count <span style="color:#f92672">=</span> train_test_features[feature]<span style="color:#f92672">.</span>value_counts()<span style="color:#f92672">.</span>max()
    <span style="color:#66d9ef">if</span> predominant_value_count <span style="color:#f92672">/</span> train_test_features<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.995</span>:
        numerical_features_to_be_dropped<span style="color:#f92672">.</span>append(feature)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Numerical features to be dropped: {numerical_features_to_be_dropped}&#39;</span>)
train_test_features <span style="color:#f92672">=</span> train_test_features<span style="color:#f92672">.</span>drop(numerical_features_to_be_dropped, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div></div>
<p class="codeoutput">Numerical features to be dropped: ['PoolArea']</p>
<h3>3.3.5. Correlation</h3>
<p>Once all numerical features have been preprocessed, it is important to verify the correlation between each numerical feature and the dependent variable, as well as correlation among numerical features leading to undesired colinearity. The heatmap below provides an overview of correlation between the dependent variable ('SalePrice') and the top 15 features mostly correlated with it, as well as correlation among them.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">features_numerical <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> column <span style="color:#f92672">in</span> train_features<span style="color:#f92672">.</span>columns:
    <span style="color:#66d9ef">if</span> train_features[column]<span style="color:#f92672">.</span>dtype <span style="color:#f92672">in</span> [<span style="color:#e6db74">&#39;int16&#39;</span>, <span style="color:#e6db74">&#39;int32&#39;</span>, <span style="color:#e6db74">&#39;int64&#39;</span>, <span style="color:#e6db74">&#39;float16&#39;</span>, <span style="color:#e6db74">&#39;float32&#39;</span>, <span style="color:#e6db74">&#39;float64&#39;</span>]:
        features_numerical<span style="color:#f92672">.</span>append(column)

updated_train_set <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([train_test_features<span style="color:#f92672">.</span>iloc[:len(train_targets), :], train_targets], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)

correlation_map(updated_train_set, <span style="color:#e6db74">&#39;SalePrice&#39;</span>, <span style="color:#ae81ff">15</span>)
</code></pre></div></div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/correl.png' alt='Correlation map'>
</div>
<p>Not surprisingly, as anticipated, features related to quality, area, number of living units and age show up as the most correlated with sale prices. This reinforces the need to devote extra attention to them.</p>
<p>Additionally, the heatmap also highlights specific correlations among pairs of features. This is the case of GarageArea and GarageCars - the rationale behind them is obvious, as larger garages accommodate a higher number of vehicles. The data scientist must therefore keep an eye on them and consider dropping one of the pair elements if signs of colinearity show up.</p>
<h2>3.4. Categorical features</h2>
<h3>3.4.1. Missing values</h3>
<p>Categorical features with missing values are identified. Their names are included in a specific list and displayed.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">missing_categorical <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> feature <span style="color:#f92672">in</span> features_categorical:
    <span style="color:#66d9ef">if</span> train_test_features<span style="color:#f92672">.</span>count()[feature] <span style="color:#f92672">&lt;</span> train_test_features<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]:
        missing_categorical<span style="color:#f92672">.</span>append(feature)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Categorical features with missing values before treatment: {len(missing_categorical)}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
<span style="color:#66d9ef">print</span>(missing_categorical)
</code></pre></div></div>
<p class="codeoutput">Categorical features with missing values before treatment: 23
['MSZoning', 'Alley', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType']</p>
<p>Replacement strategy:</p>
<ol>
    <li>MSZoning - Nulls replaced with the MSZoning mode of equivalent properties of the same class (equivalent MSSubClass values).</li>
    <li>Exterior1st, Exterior2nd, Electrical, KitchenQual, Functional, SaleType - Nulls replaced with the respective modes.</li>
    <li>All other occurrences - Nulls replaced with 'None'.</li>
</ol>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_test_features[<span style="color:#e6db74">&#39;MSZoning&#39;</span>] <span style="color:#f92672">=</span> train_test_features<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;MSSubClass&#39;</span>)[<span style="color:#e6db74">&#39;MSZoning&#39;</span>]<span style="color:#f92672">.</span>transform(<span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">.</span>fillna(x<span style="color:#f92672">.</span>mode()[<span style="color:#ae81ff">0</span>]))
train_test_features[<span style="color:#e6db74">&#39;Alley&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;Alley&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;Utilities&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;Utilities&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;Exterior1st&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;Exterior1st&#39;</span>]<span style="color:#f92672">.</span>fillna(train_test_features[<span style="color:#e6db74">&#39;Exterior1st&#39;</span>]<span style="color:#f92672">.</span>mode()[<span style="color:#ae81ff">0</span>])
train_test_features[<span style="color:#e6db74">&#39;Exterior2nd&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;Exterior2nd&#39;</span>]<span style="color:#f92672">.</span>fillna(train_test_features[<span style="color:#e6db74">&#39;Exterior2nd&#39;</span>]<span style="color:#f92672">.</span>mode()[<span style="color:#ae81ff">0</span>])
train_test_features[<span style="color:#e6db74">&#39;MasVnrType&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;MasVnrType&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtQual&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtQual&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtCond&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtCond&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtExposure&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtExposure&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtFinType1&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtFinType1&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;BsmtFinType2&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtFinType2&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;Electrical&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;Electrical&#39;</span>]<span style="color:#f92672">.</span>fillna(train_test_features[<span style="color:#e6db74">&#39;Electrical&#39;</span>]<span style="color:#f92672">.</span>mode()[<span style="color:#ae81ff">0</span>])
train_test_features[<span style="color:#e6db74">&#39;KitchenQual&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;KitchenQual&#39;</span>]<span style="color:#f92672">.</span>fillna(train_test_features[<span style="color:#e6db74">&#39;KitchenQual&#39;</span>]<span style="color:#f92672">.</span>mode()[<span style="color:#ae81ff">0</span>])
train_test_features[<span style="color:#e6db74">&#39;Functional&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;Functional&#39;</span>]<span style="color:#f92672">.</span>fillna(train_test_features[<span style="color:#e6db74">&#39;Functional&#39;</span>]<span style="color:#f92672">.</span>mode()[<span style="color:#ae81ff">0</span>])
train_test_features[<span style="color:#e6db74">&#39;FireplaceQu&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;FireplaceQu&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;GarageType&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;GarageType&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;GarageFinish&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;GarageFinish&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;GarageQual&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;GarageQual&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;GarageCond&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;GarageCond&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;PoolQC&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;PoolQC&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;Fence&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;Fence&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;MiscFeature&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;MiscFeature&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;None&#39;</span>)
train_test_features[<span style="color:#e6db74">&#39;SaleType&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;SaleType&#39;</span>]<span style="color:#f92672">.</span>fillna(train_test_features[<span style="color:#e6db74">&#39;SaleType&#39;</span>]<span style="color:#f92672">.</span>mode()[<span style="color:#ae81ff">0</span>])

missing_categorical<span style="color:#f92672">.</span>clear()
<span style="color:#66d9ef">for</span> feature <span style="color:#f92672">in</span> features_categorical:
    <span style="color:#66d9ef">if</span> train_test_features<span style="color:#f92672">.</span>count()[feature] <span style="color:#f92672">&lt;</span> train_test_features<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]:
        missing_categorical<span style="color:#f92672">.</span>append(feature)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Categorical features with missing values after treatment: {len(missing_categorical)}&#39;</span>)
</code></pre></div></div>
<h3>3.4.2. Identifying and dropping categorical features with predominant values</h3>
<p>Specific categorical features with one predominant value across all observations are barely correlated to the dependent value (sale prices) and therefore their prediction value is irrelevant. The accumulation of features with predominant values (zeros or ones in particular) may lead to sparse datasets and poorer regressions.</p>
<p>Categorical features with one predominant value present in more than 99.5% of all observations (train and test set combined) are identified and dropped. </p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">categorical_features_to_be_dropped <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> feature <span style="color:#f92672">in</span> features_categorical:
    predominant_value_count <span style="color:#f92672">=</span> train_test_features[feature]<span style="color:#f92672">.</span>value_counts()<span style="color:#f92672">.</span>max()
    <span style="color:#66d9ef">if</span> predominant_value_count <span style="color:#f92672">/</span> train_test_features<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.995</span>:
        categorical_features_to_be_dropped<span style="color:#f92672">.</span>append(feature)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Categorical features to be dropped: {categorical_features_to_be_dropped}&#39;</span>)
train_test_features <span style="color:#f92672">=</span> train_test_features<span style="color:#f92672">.</span>drop(categorical_features_to_be_dropped, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div></div>
<h3>3.4.3. Feature encoding - Categorical ordinal</h3>
<p>Categorical values must be quantified into numerical equivalents to be properly processed by machine learning algorithms. Mapped encoding is applied to categorical ordinal features, where feature values have a clear ranking nature among themselves. One hot encoding is applied to categorical nominal features, where there is no such evident ranking nature.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">map1 <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;Ex&#39;</span>: <span style="color:#ae81ff">5</span>, <span style="color:#e6db74">&#39;Gd&#39;</span>: <span style="color:#ae81ff">4</span>, <span style="color:#e6db74">&#39;TA&#39;</span>: <span style="color:#ae81ff">3</span>, <span style="color:#e6db74">&#39;Fa&#39;</span>: <span style="color:#ae81ff">2</span>, <span style="color:#e6db74">&#39;Po&#39;</span>: <span style="color:#ae81ff">1</span>, <span style="color:#e6db74">&#39;None&#39;</span>: <span style="color:#ae81ff">0</span>}
set1 <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;ExterQual&#39;</span>, <span style="color:#e6db74">&#39;ExterCond&#39;</span>, <span style="color:#e6db74">&#39;BsmtQual&#39;</span>,<span style="color:#e6db74">&#39;BsmtCond&#39;</span>, <span style="color:#e6db74">&#39;HeatingQC&#39;</span>,
        <span style="color:#e6db74">&#39;KitchenQual&#39;</span>, <span style="color:#e6db74">&#39;FireplaceQu&#39;</span>, <span style="color:#e6db74">&#39;GarageQual&#39;</span>, <span style="color:#e6db74">&#39;GarageCond&#39;</span>]
<span style="color:#66d9ef">for</span> feature <span style="color:#f92672">in</span> set1:
    train_test_features[feature] <span style="color:#f92672">=</span> train_test_features[feature]<span style="color:#f92672">.</span>replace(map1)

map2 <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;Gd&#39;</span>: <span style="color:#ae81ff">4</span>, <span style="color:#e6db74">&#39;Av&#39;</span>: <span style="color:#ae81ff">3</span>, <span style="color:#e6db74">&#39;Mn&#39;</span>: <span style="color:#ae81ff">2</span>, <span style="color:#e6db74">&#39;No&#39;</span>: <span style="color:#ae81ff">1</span>, <span style="color:#e6db74">&#39;None&#39;</span>: <span style="color:#ae81ff">0</span>}
train_test_features[<span style="color:#e6db74">&#39;BsmtExposure&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;BsmtExposure&#39;</span>]<span style="color:#f92672">.</span>replace(map2)

map3 <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;GLQ&#39;</span>: <span style="color:#ae81ff">4</span>,<span style="color:#e6db74">&#39;ALQ&#39;</span>: <span style="color:#ae81ff">3</span>,<span style="color:#e6db74">&#39;BLQ&#39;</span>: <span style="color:#ae81ff">2</span>,<span style="color:#e6db74">&#39;Rec&#39;</span>: <span style="color:#ae81ff">3</span>,<span style="color:#e6db74">&#39;LwQ&#39;</span>: <span style="color:#ae81ff">2</span>,<span style="color:#e6db74">&#39;Unf&#39;</span>: <span style="color:#ae81ff">1</span>,<span style="color:#e6db74">&#39;None&#39;</span>: <span style="color:#ae81ff">0</span>}
set3 <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;BsmtFinType1&#39;</span>, <span style="color:#e6db74">&#39;BsmtFinType2&#39;</span>]
<span style="color:#66d9ef">for</span> feature <span style="color:#f92672">in</span> set3:
    train_test_features[feature] <span style="color:#f92672">=</span> train_test_features[feature]<span style="color:#f92672">.</span>replace(map3)

map4 <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;Y&#39;</span>: <span style="color:#ae81ff">1</span>, <span style="color:#e6db74">&#39;N&#39;</span>: <span style="color:#ae81ff">0</span>}
train_test_features[<span style="color:#e6db74">&#39;CentralAir&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;CentralAir&#39;</span>]<span style="color:#f92672">.</span>replace(map4)

map5 <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;Typ&#39;</span>: <span style="color:#ae81ff">3</span>, <span style="color:#e6db74">&#39;Min1&#39;</span>: <span style="color:#ae81ff">2.5</span>, <span style="color:#e6db74">&#39;Min2&#39;</span>: <span style="color:#ae81ff">2</span>, <span style="color:#e6db74">&#39;Mod&#39;</span>: <span style="color:#ae81ff">1.5</span>, <span style="color:#e6db74">&#39;Maj1&#39;</span>: <span style="color:#ae81ff">1</span>, <span style="color:#e6db74">&#39;Maj2&#39;</span>: <span style="color:#ae81ff">0.5</span>, <span style="color:#e6db74">&#39;Sev&#39;</span>: <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#39;Sal&#39;</span>: <span style="color:#ae81ff">0</span>}
train_test_features[<span style="color:#e6db74">&#39;Functional&#39;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#39;Functional&#39;</span>]<span style="color:#f92672">.</span>replace(map5)
</code></pre></div></div>
<h3>3.4.4. Creation of new features from coded categorical ordinal features</h3>
<p>Similar to what was proposed for numerical features, additional features may be derived from recently coded categorical features to emphasize key aspects of the problem under analysis. Here two new features are proposed to enhance property quality aspects:</p>
<ul>
    <li>Total garage quality, as the product of garage quality and garage conditions;</li>
    <li>Total exterior quality, as the product of exterior quality and exterior conditions.</li>
</ul>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_test_features[<span style="color:#e6db74">&#34;TotalGarageQual&#34;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#34;GarageQual&#34;</span>] <span style="color:#f92672">*</span> train_test_features[<span style="color:#e6db74">&#34;GarageCond&#34;</span>]
train_test_features[<span style="color:#e6db74">&#34;TotalExteriorQual&#34;</span>] <span style="color:#f92672">=</span> train_test_features[<span style="color:#e6db74">&#34;ExterQual&#34;</span>] <span style="color:#f92672">*</span> train_test_features[<span style="color:#e6db74">&#34;ExterCond&#34;</span>]
</code></pre></div></div>
<h3>3.4.5. Feature encoding - Categorical nominal</h3>
<p>One hot encoding is applied to categorical nominal features, where there is no evident ranking nature among categories. Please note that the Pandas 'get_dummies' method is applied to the whole 'train_test_features' dataframe. Existing numerical features will not be affected by this operation and remain as they are. Only categorical features will be coded hereby.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_test_features <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>get_dummies(train_test_features)<span style="color:#f92672">.</span>reset_index(drop<span style="color:#f92672">=</span>True)
</code></pre></div></div>
<h2>3.5. Dependent variable (SalePrice) treatment</h2>
<p>The dependent variable is right skewed (i.e. lower value observations are predominant and higher value observations are dispersed over a longer right tail). Normalization of the dependent variable through log transformation is highly recommended and performed.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_targets_skew <span style="color:#f92672">=</span> skew(train_targets)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;Dependent variable skew factor: {train_targets_skew:.2f}&#39;</span>)
</code></pre></div></div>
<p class="codeoutput">Dependent variable skew factor: 1.88</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y_train <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>log1p(train_targets)
</code></pre></div></div>
<p>The charts below illustrate the dependent variable distribution before and after log transformation.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fig, ax <span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>,<span style="color:#ae81ff">4</span>))
chart1 <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>distplot(train_targets, ax<span style="color:#f92672">=</span>ax[<span style="color:#ae81ff">0</span>], color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;b&#39;</span>)
chart1<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;SalePrice&#39;</span>,fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
chart2 <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>distplot(y_train, ax<span style="color:#f92672">=</span>ax[<span style="color:#ae81ff">1</span>], color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;g&#39;</span>)
chart2<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;SalePrice&#39;</span>,fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
fig<span style="color:#f92672">.</span>show()
</code></pre></div></div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/dependent.png' alt='Dependent variable normalization'>
</div>
<h2>3.6. Segregating train and test features</h2>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X_train <span style="color:#f92672">=</span> train_test_features<span style="color:#f92672">.</span>iloc[:len(train_targets), :]
X_test <span style="color:#f92672">=</span> train_test_features<span style="color:#f92672">.</span>iloc[len(train_targets):, :]
X_train_data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([X_train, y_train], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div></div>
<h2>3.7. Optimizing the training set before regression</h2>
<p>In preparation for machine learning regressions, a final optimization of the training set is recommended after train and test sets have been segregated. At this point, interest resides in two very important aspects:</p>
<ul>
    <li>Features with 'zero' as the predominant value</li>
    <li>Outliers</li>
</ul>
<h3>3.7.1. Features with 'zero' as the predominant value</h3>
<p>The accumulation of features with 'zero' as their predominant value (in particular those that may have been created over one hot encoding) may lead to potential overfitting. In other words, the regression models may attempt to fit (read "accommodate") to a very limited number of 'ones' present in such features and, as a consequence, their overall performance is negatively impacted. Eliminating features with a significant relative number of zeros is highly recommended. The same threshold (99.5%) adopted in Sections 3.3.4. and 3.4.2. is considered here.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">features_to_be_dropped <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> feature <span style="color:#f92672">in</span> X_train<span style="color:#f92672">.</span>columns:
    all_value_counts <span style="color:#f92672">=</span> X_train[feature]<span style="color:#f92672">.</span>value_counts()
    zero_value_counts <span style="color:#f92672">=</span> all_value_counts<span style="color:#f92672">.</span>iloc[<span style="color:#ae81ff">0</span>]
    <span style="color:#66d9ef">if</span> zero_value_counts <span style="color:#f92672">/</span> len(X_train) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.995</span>:
        features_to_be_dropped<span style="color:#f92672">.</span>append(feature)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Features with predominant zeroes:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
<span style="color:#66d9ef">print</span>(features_to_be_dropped)

X_train <span style="color:#f92672">=</span> X_train<span style="color:#f92672">.</span>drop(features_to_be_dropped, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>copy()
X_test <span style="color:#f92672">=</span> X_test<span style="color:#f92672">.</span>drop(features_to_be_dropped, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>copy()
X_train_data <span style="color:#f92672">=</span> X_train_data<span style="color:#f92672">.</span>drop(features_to_be_dropped, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>copy()
</code></pre></div></div>
<p class="codeoutput">Features with predominant zeroes:
['MSSubClass_150', 'MSSubClass_40', 'LotConfig_FR3', 'Neighborhood_Blueste', 'Condition1_RRNe', 'Condition1_RRNn', 'Condition2_Artery', 'Condition2_Feedr', 'Condition2_PosA', 'Condition2_PosN', 'Condition2_RRAe', 'Condition2_RRAn', 'Condition2_RRNn', 'RoofStyle_Mansard', 'RoofStyle_Shed', 'RoofMatl_ClyTile', 'RoofMatl_Membran', 'RoofMatl_Metal', 'RoofMatl_Roll', 'RoofMatl_WdShake', 'RoofMatl_WdShngl', 'Exterior1st_AsphShn', 'Exterior1st_BrkComm', 'Exterior1st_CBlock', 'Exterior1st_ImStucc', 'Exterior1st_Stone', 'Exterior2nd_AsphShn', 'Exterior2nd_Brk Cmn', 'Exterior2nd_CBlock', 'Exterior2nd_Other', 'Exterior2nd_Stone', 'Foundation_Stone', 'Foundation_Wood', 'Heating_Floor', 'Heating_Grav', 'Heating_OthW', 'Heating_Wall', 'Electrical_FuseP', 'Electrical_Mix', 'GarageType_2Types', 'MiscFeature_Gar2', 'MiscFeature_Othr', 'MiscFeature_TenC', 'SaleType_CWD', 'SaleType_Con', 'SaleType_ConLI', 'SaleType_ConLw', 'SaleType_Oth', 'SaleCondition_AdjLand']</p>
<h3>3.7.2. Outliers</h3>
<p>The presence of observations with one or more feature values diverging significantly from the general correlation pattern - called outliers - can also lead to overfitting. Removal of such observations is highly recommended.</p>
<p>However, when the number of observations and/or features is high, the graphical identification of outliers via chart analysis is impractical.</p>
<p>In this exercise an intelligent, automated and quantifiable approach is proposed. A particular regressor with cross-validation capabilities (LassoCV) is utilized. Regressions are iteratively executed and regression metrics (score mean and score standard deviation) are calculated. In each iteration, one specific observation is excluded from the exercise. If that observation is an outlier, regression metrics are expected to slightly improve as a result of its exclusion. After the last iteration, observations whose exclusion led to metrics improvements are identified.</p>
<p>The dropping procedure is executed for one observation at a time. At first, the most impacting observation is removed and the score is calculated. Subsequently, the second observation is also dropped, and the score is recalculated. The process is recurrently (and here manually) repeated until the regression score starts to deteriorate - at this point the n-th observation removed may carry relevant information for the overall regression and its removal negatively impacts the regression results. Time to stop.</p>
<p>Please note that this step is time/resource consuming. Accordingly, the code provided in Section 3.8.1. is commented out and must be executed only once, allowing for proper outlier mapping. Graphical inspection may be performed with the code supplied in Section 3.8.2. The outliers identified in this exercise are listed in Section 3.8.3. and dropped prior to the subsequent regression program.</p>
<h4>3.7.2.1. Identifying relevant outliers with regression assistance</h4>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># lasso_alphas = [5e-5, 1e-4, 5e-4, 1e-3]</span>
<span style="color:#75715e"># lasso_outliers = make_pipeline(RobustScaler(),</span>
<span style="color:#75715e">#                       LassoCV(max_iter=1e7, alphas=lasso_alphas,</span>
<span style="color:#75715e">#                               random_state=42, cv=4))</span>

<span style="color:#75715e"># print(f&#39;{&#34;Identifying relevant outliers with LassoCV&#34;}&#39;)</span>
<span style="color:#75715e"># score = xval_rmse_scoring(lasso_outliers, X_train, y_train, 4)</span>
<span style="color:#75715e"># print(f&#39;{&#34;All obs&#34;:&lt;10}{score.mean():&gt;14.8f}{score.std():&gt;14.8f}&#39;)</span>

<span style="color:#75715e"># outlier_mean = []</span>
<span style="color:#75715e"># outlier_stdev = []</span>

<span style="color:#75715e"># for i in range(len(X_train)):</span>
<span style="color:#75715e">#     X_new = X_train.copy()</span>
<span style="color:#75715e">#     y_new = y_train.copy()</span>
<span style="color:#75715e">#     X_new = X_new.drop(X_new.index[i])</span>
<span style="color:#75715e">#     y_new = y_new.drop(y_new.index[i])</span>
<span style="color:#75715e">#     score = xval_rmse_scoring(lasso_outliers, X_new, y_new, 4)</span>
<span style="color:#75715e">#     outlier_mean.append(score.mean())</span>
<span style="color:#75715e">#     outlier_stdev.append(score.std())</span>
<span style="color:#75715e">#     print(f&#39;{&#34;Obs &#34;:4}{i:&lt;6}{score.mean():&gt;14.8f}{score.std():&gt;14.8f}&#39;)</span>

<span style="color:#75715e"># outlier_impact = pd.DataFrame(list(zip(outlier_mean, outlier_stdev)), columns =[&#39;Mean&#39;, &#39;St Dev&#39;])</span>
<span style="color:#75715e"># outlier_lower_mean = outlier_impact.sort_values(by=[&#39;Mean&#39;], ascending=True)</span>
<span style="color:#75715e"># outlier_lower_stdev = outlier_impact.sort_values(by=[&#39;St Dev&#39;], ascending=True)</span>
<span style="color:#75715e"># outlier_impact.to_csv(&#39;outlier_impact.csv&#39;)</span>
</code></pre></div></div>
<h4>3.7.2.2. Outlier inspection</h4>
<p>The example below highlights outliers identified for observations with IDs 523 and 1298. In both cases values for the feature 'GrLivArea' (red dots on the scatter charts at right) evidently diverge from the prevailing correlation pattern.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">assessment(X_train_data, <span style="color:#e6db74">&#39;SalePrice&#39;</span>, <span style="color:#e6db74">&#39;GrLivArea&#39;</span>, <span style="color:#ae81ff">523</span>)
assessment(X_train_data, <span style="color:#e6db74">&#39;SalePrice&#39;</span>, <span style="color:#e6db74">&#39;GrLivArea&#39;</span>, <span style="color:#ae81ff">1298</span>)
</code></pre></div></div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/outliers-1.png' alt='Outlier 1'>
</div>
<div class='row'>
    <img class="imageboxcentered" src='/house-pricing/images/outliers-2.png' alt='Outlier 2'>
</div>
<h4>3.7.2.3. Outlier removal</h4>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">outliers <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1298</span>, <span style="color:#ae81ff">523</span>, <span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">462</span>, <span style="color:#ae81ff">588</span>, <span style="color:#ae81ff">632</span>, <span style="color:#ae81ff">1324</span>]
X_train <span style="color:#f92672">=</span> X_train<span style="color:#f92672">.</span>drop(X_train<span style="color:#f92672">.</span>index[outliers])
y_train <span style="color:#f92672">=</span> y_train<span style="color:#f92672">.</span>drop(y_train<span style="color:#f92672">.</span>index[outliers])
</code></pre></div></div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-04-machine-learning" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>4. Machine learning - Advanced regression</h1>
<p>An advanced, cross-validation supported regression approach is proposed herein. The strategy includes:</p>
<ol>
    <li>Generation of 'n' predictions from a set of 'n' selected regression engines (models);</li>
    <li>Generation of an additional prediction from one selected stacking model, which aggregates predictions from the 'n' regression engines utilized in (1);</li>
    <li>Generation of a final prediction through a blending mechanism combining weighed predictions from each of the 'n' predictions obtained in (1) plus the prediction of the stacking model obtained in (2).</li>
</ol>
<h2>4.1. Cross-validation setup</h2>
<p>KFold has been elected as the cross-validation engine of choice in this exercise. The training set is splitted in 10 folds. One fold is iteratively used at a time as a validation set.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">kfolds <span style="color:#f92672">=</span> KFold(n_splits<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, shuffle<span style="color:#f92672">=</span>True, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</code></pre></div></div>
<h2>4.2. Model definition</h2>
<p>Six regression models (ElasticNetCV, LassoCV, RidgeCV, GradientBoostingRegressor, SVR and XGBoost), covering a variety of regression strategies, techniques, cross-validation capabilities and regularization features, have been elected in this exercise. Each of them has been individually tuned to minimize error metrics and best fit the training set. Referring to the each regressor documentation is highly recommended (clickable links provided in Section 2.1.). The parameters listed below are the best obtained from these individual fitting rounds.</p>
<p>Two additional regressors have also been considered:</p>
<ul>
    <li>RandomForestRegressor did not provide any substantial improvement to performance metrics and was discarded;</li>
    <li>CatBoostRegressor marginally contributed to performance metric improvements but was at last discarded due to its extremely long execution time (not even the recommendations provided <a href="https://catboost.ai/docs/concepts/speed-up-training.html" target="_blank">here</a> sufficed to reduce the execution time penalty).</li>
</ul>
<p>StackingCV has been chosen as the stacking regressor. In summary, StackingCV collects predictions derived from the six primary regressors and, making use of one of them, denominated 'meta regressor' (XGBoost was chosen in this exercise), produces a combined ('stacked') prediction.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">elasticnet_alphas <span style="color:#f92672">=</span> [<span style="color:#ae81ff">5e-5</span>, <span style="color:#ae81ff">1e-4</span>, <span style="color:#ae81ff">5e-4</span>, <span style="color:#ae81ff">1e-3</span>]
elasticnet_l1ratios <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">0.85</span>, <span style="color:#ae81ff">0.9</span>, <span style="color:#ae81ff">0.95</span>, <span style="color:#ae81ff">1</span>]
elasticnet <span style="color:#f92672">=</span> make_pipeline(RobustScaler(),
                           ElasticNetCV(max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">1e7</span>, alphas<span style="color:#f92672">=</span>elasticnet_alphas,
                                        cv<span style="color:#f92672">=</span>kfolds, l1_ratio<span style="color:#f92672">=</span>elasticnet_l1ratios))

lasso_alphas <span style="color:#f92672">=</span> [<span style="color:#ae81ff">5e-5</span>, <span style="color:#ae81ff">1e-4</span>, <span style="color:#ae81ff">5e-4</span>, <span style="color:#ae81ff">1e-3</span>]
lasso <span style="color:#f92672">=</span> make_pipeline(RobustScaler(),
                      LassoCV(max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">1e7</span>, alphas<span style="color:#f92672">=</span>lasso_alphas,
                              random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, cv<span style="color:#f92672">=</span>kfolds))

ridge_alphas <span style="color:#f92672">=</span> [<span style="color:#ae81ff">13.5</span>, <span style="color:#ae81ff">14</span>, <span style="color:#ae81ff">14.5</span>, <span style="color:#ae81ff">15</span>, <span style="color:#ae81ff">15.5</span>]
ridge <span style="color:#f92672">=</span> make_pipeline(RobustScaler(),
                      RidgeCV(alphas<span style="color:#f92672">=</span>ridge_alphas, cv<span style="color:#f92672">=</span>kfolds))

gradb <span style="color:#f92672">=</span> GradientBoostingRegressor(n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">6000</span>, learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>,
                                  max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, max_features<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sqrt&#39;</span>,
                                  min_samples_leaf<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>, min_samples_split<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
                                  loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;huber&#39;</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)

svr <span style="color:#f92672">=</span> make_pipeline(RobustScaler(),
                    SVR(C<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>, epsilon<span style="color:#f92672">=</span><span style="color:#ae81ff">0.008</span>, gamma<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0003</span>))

xgboost <span style="color:#f92672">=</span> XGBRegressor(learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">6000</span>,
                       max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, min_child_weight<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
                       gamma<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, subsample<span style="color:#f92672">=</span><span style="color:#ae81ff">0.7</span>,
                       colsample_bytree<span style="color:#f92672">=</span><span style="color:#ae81ff">0.7</span>,
                       objective<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;reg:squarederror&#39;</span>, nthread<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>,
                       scale_pos_weight<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, seed<span style="color:#f92672">=</span><span style="color:#ae81ff">27</span>,
                       reg_alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.00006</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)

stackcv <span style="color:#f92672">=</span> StackingCVRegressor(regressors<span style="color:#f92672">=</span>(elasticnet, gradb, lasso, 
                                          ridge, svr, xgboost),
                              meta_regressor<span style="color:#f92672">=</span>xgboost,
                              use_features_in_secondary<span style="color:#f92672">=</span>True)
</code></pre></div></div>
<h2>4.3. Individual model performance on cross-validation</h2>
<p>Each of the six elected regression models is hereby submitted to scoring based on the Root Mean Squared Error (RMSE) metric (mean and standard deviation provided through cross-validation). This step offers a first glance at individual model performance and is intended to support and frame subsequent stacking and blending phases.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Individual model scoring on cross-validation</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;Model&#34;:&lt;20}{&#34;RMSE mean&#34;:&gt;12}{&#34;RMSE stdev&#34;:&gt;12}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)

score <span style="color:#f92672">=</span> xval_rmse_scoring(elasticnet, X_train, y_train, kfolds)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;1. ElasticNetCV&#34;:&lt;20}{score.mean():&gt;12.4f}{score.std():&gt;12.4f}&#39;</span>)

score <span style="color:#f92672">=</span> xval_rmse_scoring(lasso, X_train, y_train, kfolds)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;2. LassoCV&#34;:&lt;20}{score.mean():&gt;12.4f}{score.std():&gt;12.4f}&#39;</span>)

score <span style="color:#f92672">=</span> xval_rmse_scoring(ridge, X_train, y_train, kfolds)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;3. RidgeCV&#34;:&lt;20}{score.mean():&gt;12.4f}{score.std():&gt;12.4f}&#39;</span>)

score <span style="color:#f92672">=</span> xval_rmse_scoring(gradb, X_train, y_train, kfolds)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;4. GradientBoosting&#34;:&lt;20}{score.mean():&gt;12.4f}{score.std():&gt;12.4f}&#39;</span>)

score <span style="color:#f92672">=</span> xval_rmse_scoring(svr, X_train, y_train, kfolds)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;5. SVR&#34;:&lt;20}{score.mean():&gt;12.4f}{score.std():&gt;12.4f}&#39;</span>)

score <span style="color:#f92672">=</span> xval_rmse_scoring(xgboost, X_train, y_train, kfolds)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;6. XGBoost&#34;:&lt;20}{score.mean():&gt;12.4f}{score.std():&gt;12.4f}&#39;</span>)
</code></pre></div></div>
<table>
    <tbody class="codeoutput">
        <tr>
            <td style="width: 50%; border: 0;">Individual model scoring on cross-validation</td>
            <td style="width: 25%; border: 0;"></td>
            <td style="width: 25%; border: 0;"></td>
        </tr>
        <tr>
            <td style="width: 50%; border: 0;">Model</td>
            <td style="width: 25%; border: 0;">RMSE mean</td>
            <td style="width: 25%; border: 0;">RMSE stdev</td>
        </tr>
        <tr>
            <td style="width: 50%; border: 0;">1. ElasticNetCV</td>
            <td style="width: 25%; border: 0;">0.1002</td>
            <td style="width: 25%; border: 0;">0.0157</td>
        </tr>
        <tr>
            <td style="width: 50%; border: 0;">2. LassoCV</td>
            <td style="width: 25%; border: 0;">0.1002</td>
            <td style="width: 25%; border: 0;">0.0158</td>
        </tr>
        <tr>
            <td style="width: 50%; border: 0;">3. RidgeCV</td>
            <td style="width: 25%; border: 0;">0.1012</td>
            <td style="width: 25%; border: 0;">0.0159</td>
        </tr>
        <tr>
            <td style="width: 50%; border: 0;">4. GradientBoosting</td>
            <td style="width: 25%; border: 0;">0.1043</td>
            <td style="width: 25%; border: 0;">0.0191</td>
        </tr>
        <tr>
            <td style="width: 50%; border: 0;">5. SVR</td>
            <td style="width: 25%; border: 0;">0.1020</td>
            <td style="width: 25%; border: 0;">0.0174</td>
        </tr>
        <tr>
            <td style="width: 50%; border: 0;">6. XGBoost</td>
            <td style="width: 25%; border: 0;">0.1021</td>
            <td style="width: 25%; border: 0;">0.0156</td>
        </tr>
    </tbody>
</table>
<h2>4.4. Individual model fitting to the training set</h2>
<p>Here the six primary regressors and the stacking regressor are fitted to the training set.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Fitting individual models to the training set</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;1. ElasticNetCV...&#34;:&lt;20}&#39;</span>)
elastic_fit <span style="color:#f92672">=</span> elasticnet<span style="color:#f92672">.</span>fit(X_train, y_train)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;2. LassoCV...&#34;:&lt;20}&#39;</span>)
lasso_fit <span style="color:#f92672">=</span> lasso<span style="color:#f92672">.</span>fit(X_train, y_train)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;3. RidgeCV...&#34;:&lt;20}&#39;</span>)
ridge_fit <span style="color:#f92672">=</span> ridge<span style="color:#f92672">.</span>fit(X_train, y_train)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;4. GradientBoosting...&#34;:&lt;20}&#39;</span>)
gradb_fit <span style="color:#f92672">=</span> gradb<span style="color:#f92672">.</span>fit(X_train, y_train)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;5. SVR...&#34;:&lt;20}&#39;</span>)
svr_fit <span style="color:#f92672">=</span> svr<span style="color:#f92672">.</span>fit(X_train, y_train)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;6. XGBoost...&#34;:&lt;20}&#39;</span>)
xgb_fit <span style="color:#f92672">=</span> xgboost<span style="color:#f92672">.</span>fit(X_train, y_train)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Fitting the stacking model to the training set</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;StackingCV...&#34;:&lt;20}&#39;</span>)
stackcv_fit <span style="color:#f92672">=</span> stackcv<span style="color:#f92672">.</span>fit(np<span style="color:#f92672">.</span>array(X_train), np<span style="color:#f92672">.</span>array(y_train))
</code></pre></div></div>
<p class="codeoutput">Fitting individual models to the training set<br />
1. ElasticNetCV...<br />
2. LassoCV...<br />
3. RidgeCV...<br />
4. GradientBoosting...<br />
5. SVR...<br />
6. XGBoost...<br />
Fitting the stacking model to the training set<br />
StackingCV...</p>
<h2>4.5. Blend model construction</h2>
<p>Blending proved extremely helpful on the enhancement of error metrics in this exercise. A slight modification in weights attributed to individual regression inputs (predictions on the training set) led to either awesome improvements or awful deteriorations of error metrics.</p>
<p>A manual, detailed (though time consuming...) weight adjustment program was executed. Starting from a set of uniformly distributed weights for each prediction, weights were manually redistributed with a 1% minimum granularity. In practical terms, the method consisted in manually decreasing the weight of one particular prediction in 1%, manually increasing the weight of another particular prediction in 1% and observing the impact of such changes on the error metrics. The procedure was repeated iteratively until no further improvement of error estimates was achieved.</p>
<p>The list below reproduces the weights obtained after the optimization procedure described above.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">blend_weights <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.11</span>, <span style="color:#ae81ff">0.05</span>, <span style="color:#ae81ff">0.00</span>, <span style="color:#ae81ff">0.14</span>, <span style="color:#ae81ff">0.43</span>, <span style="color:#ae81ff">0.00</span>, <span style="color:#ae81ff">0.27</span>]
</code></pre></div></div>
<p>Interestingly, weights associated with individually best performing regressors have their weights reduced during the weight optimization process. SVR accounts for most of the contribution to improved results, while RidgeCV and XGBoost have their contributions (surprisingly?) eclipsed by other regressors. As expected, StackingCV performed well and ranks second as a contributor.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y_train <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>expm1(y_train)
y_pred <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>expm1((blend_weights[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">*</span> elastic_fit<span style="color:#f92672">.</span>predict(X_train)) <span style="color:#f92672">+</span>
                  (blend_weights[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">*</span> lasso_fit<span style="color:#f92672">.</span>predict(X_train)) <span style="color:#f92672">+</span>
                  (blend_weights[<span style="color:#ae81ff">2</span>] <span style="color:#f92672">*</span> ridge_fit<span style="color:#f92672">.</span>predict(X_train)) <span style="color:#f92672">+</span>
                  (blend_weights[<span style="color:#ae81ff">3</span>] <span style="color:#f92672">*</span> svr_fit<span style="color:#f92672">.</span>predict(X_train)) <span style="color:#f92672">+</span>
                  (blend_weights[<span style="color:#ae81ff">4</span>] <span style="color:#f92672">*</span> gradb_fit<span style="color:#f92672">.</span>predict(X_train)) <span style="color:#f92672">+</span>
                  (blend_weights[<span style="color:#ae81ff">5</span>] <span style="color:#f92672">*</span> xgb_fit<span style="color:#f92672">.</span>predict(X_train)) <span style="color:#f92672">+</span>
                  (blend_weights[<span style="color:#ae81ff">6</span>] <span style="color:#f92672">*</span> stackcv_fit<span style="color:#f92672">.</span>predict(np<span style="color:#f92672">.</span>array(X_train))))
</code></pre></div></div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-05-results" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>5. Results</h1>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">rmse <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(mean_squared_error(y_train, y_pred))
rmsle <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(mean_squared_log_error(y_train, y_pred))
mae <span style="color:#f92672">=</span> mean_absolute_error(y_train, y_pred)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Blend model performance on the training set</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;RMSE&#34;:&lt;7} {rmse:&gt;15.8f}&#39;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;RMSLE&#34;:&lt;7} {rmsle:&gt;15.8f}&#39;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;{&#34;MAE&#34;:&lt;7} {mae:&gt;15.8f}&#39;</span>)
</code></pre></div></div>
<table>
    <tbody class="codeoutput">
        <tr>
            <td style="width: 70%; border: 0;">Blend model performance on the training set</td>
            <td style="width: 30%; border: 0;"></td>
        </tr>
        <tr>
            <td style="width: 70%; border: 0;">RMSE</td>
            <td style="width: 30%; border: 0;">8968.79293271</td>
        </tr>
        <tr>
            <td style="width: 70%; border: 0;">RMSLE</td>
            <td style="width: 30%; border: 0;">0.05219165</td>
        </tr>
        <tr>
            <td style="width: 70%; border: 0;">MAE</td>
            <td style="width: 30%; border: 0;">5642.86255414</td>
        </tr>
    </tbody>
</table>
<p>The commented code below enables generating and saving a contribution to the competition.</p>
<div class="boxborder">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># print(&#39;\nGenerating submission&#39;)</span>
<span style="color:#75715e"># submission = pd.read_csv(&#39;submission.csv&#39;)</span>
<span style="color:#75715e"># submission.iloc[:, 1] = np.round_(np.expm1((blend_weights[0] * elastic_fit.predict(X_test)) +</span>
<span style="color:#75715e">#                                            (blend_weights[1] * lasso_fit.predict(X_test)) +</span>
<span style="color:#75715e">#                                            (blend_weights[2] * ridge_fit.predict(X_test)) +</span>
<span style="color:#75715e">#                                            (blend_weights[3] * svr_fit.predict(X_test)) +</span>
<span style="color:#75715e">#                                            (blend_weights[4] * gradb_fit.predict(X_test)) +</span>
<span style="color:#75715e">#                                            (blend_weights[5] * xgb_fit.predict(X_test)) +</span>
<span style="color:#75715e">#                                            (blend_weights[6] * stackcv_fit.predict(np.array(X_test)))))</span>
<span style="color:#75715e"># submission.to_csv(&#39;submission_new.csv&#39;, index=False)</span>
<span style="color:#75715e"># print(&#39;Submission saved&#39;)</span>

end_time <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Start time&#39;</span>, start_time)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;End time&#39;</span>, end_time)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Time elapsed&#39;</span>, end_time <span style="color:#f92672">-</span> start_time)
</code></pre></div></div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-06-discussion-and-final-remarks" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>6. Discussion and final remarks</h1>
<p>Few specific aspects of this exercise demand special consideration:</p>
<ol>
    <li>A significant amount of time was spent on preprocessing (as it should). In particular, different missing value replacement strategies and alternative categoric feature coding mechanisms were investigated. As an example, the mapped encoding proposed in Section 3.4.3. was replaced with one hot encoding and, as expected, did not did not lead to better predictions. Also, the role of additional features created in Sections 3.3.2. and 3.4.4. contributed positively to enhance results.</li>
    <li>A special attention to the selection of outliers is strongly recommended.  The experience in this exercise showed that the maintenance or removal of each top impacting outlier mapped with regression assistance had a major impact on the final error estimates, confirming that they indeed add up to compounded error metrics, negatively afftecting the overall regression performance.</li>
    <li>Substantially better error metrics were achieved through the proposed 'stack and blend' strategy. Individual regressors alone did not perform as well as the blended model. An automated weight adjustment code is an enhancement considered for further releases of this exercise.</li>
</ol>
<p>The mean absolute error obtained in Section 5 (for the training set - always important to mention!) serves as an indication of what might be obtained with the testing set and with new data the algorithm may be confronted with. In fact, the predictions submitted to Kaggle's competition achieved a MAE score of 11,847.22 (12th position in the ranking on April 25th, 2020), about twice the metric obtained with the training set. This might be an indication of overfitting on the training set as a result of aggressive optimization of the blend model weights. In order to test this hypothesis, two other submissions obtained from more conservative blend regressions were presented with no improvement observed on the test set.</p>
<p>Machine learning aims primarily at enabling predictions. However, the error metric itself - an average error - may also serve other practical purposes. As an example, a MAE between USD 5k-6k like the one obtained with the training set might be used by a seller as a price margin to be considered when the property is listed and further negotiated with a potential buyer, although in relative terms such margin may be more or less representative (a USD 5-6k margin weighs more on a USD 40k property than on a USD 200k estate).</p>

    </div>
  
</div>

    </div>
  </section>



      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js" integrity="sha512-7t8APmYpzEsZP7CYoA7RfMPV9Bb+PJHa9x2WiUnDXZx3XHveuyWUtvNOexhkierl5flZ3tr92dP1mMS+SGlD+A==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/python.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.3b2b658c61ebd725bd5fc606c89fe44c.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms of Service</a>
    
  </p>
  

  <p class="powered-by">
    © 2020 Paulo Breviglieri - All rights reserved
  </p>

</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
