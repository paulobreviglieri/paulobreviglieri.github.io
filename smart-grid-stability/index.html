<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  

  
  
  
  
  
  

  

  
  
  
    
  
  <meta name="description" content="">

  
  <link rel="alternate" hreflang="en-us" href="https://pcbreviglieri.github.io/smart-grid-stability/">

  


  
  
  
  <meta name="theme-color" content="#000080">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/atom-one-light.min.css" crossorigin="anonymous" title="hl-light">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/atom-one-light.min.css" crossorigin="anonymous" title="hl-dark" disabled>
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Oxygen:300light,400,700bold%7COxygen+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hue0b5dbdcd29e15f3bb2c3e480ec18a0b_14701_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hue0b5dbdcd29e15f3bb2c3e480ec18a0b_14701_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://pcbreviglieri.github.io/smart-grid-stability/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@pcbreviglieri">
  <meta property="twitter:creator" content="@pcbreviglieri">
  
  <meta property="og:site_name" content="Paulo Breviglieri">
  <meta property="og:url" content="https://pcbreviglieri.github.io/smart-grid-stability/">
  <meta property="og:title" content="Smart Grid Stability with Deep Learning | Paulo Breviglieri">
  <meta property="og:description" content=""><meta property="og:image" content="https://pcbreviglieri.github.io/images/icon_hue0b5dbdcd29e15f3bb2c3e480ec18a0b_14701_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="https://pcbreviglieri.github.io/images/icon_hue0b5dbdcd29e15f3bb2c3e480ec18a0b_14701_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-01-01T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-01-01T00:00:00&#43;00:00">
  

  



  


  


  





  <title>Smart Grid Stability with Deep Learning | Paulo Breviglieri</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" class=" ">

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Paulo Breviglieri</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Paulo Breviglieri</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/portfolio"><span>Portfolio</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/about"><span>About</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      

      

    </ul>

  </div>
</nav>



  
<span class="js-widget-page d-none"></span>





  
  
  
  




  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-00-social-icons" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <div class="container-social">
    <div class="fab fa-linkedin" style="color: #2867b2;" onclick="window.open('https://linkedin.com/in/pcbreviglieri')"></div>
    <div class="fab fa-twitter-square" style="color: #1da1f2;" onclick="window.open('https://twitter.com/pcbreviglieri')"></div>
    <div class="fab fa-github-square" style="color: #333333;" onclick="window.open('https://github.com/pcbreviglieri')"></div>
    <div class="fab fa-stack-overflow" style="color: #f48024;" onclick="window.open('https://stackoverflow.com/story/pcbreviglieri')"></div>
    <div class="fab fa-telegram-plane" style="color: #0088cc;" onclick="window.open('https://t.me/pcbreviglieri')"></div>
    <div class="fas fa-envelope-square" style="color: #dd0000;" onclick="window.open('mailto:info@paulobreviglieri.com')"></div>
</div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-foreword" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1 style="text-align: center; font-size: 30px; color: #ff3000;">Smart Grid Stability with Deep Learning</h1>
<p>May 9, 2020 - By Paulo Breviglieri</p>
<h1>Foreword</h1>
<p>This study is based on the "<b>Electrical Grid Stability Simulated Dataset</b>", created by Vadim Arzamasov (Karlsruher Institut für Technologie, Karlsruhe, Germany) and donated to the <b>University of California (UCI) Machine Learning Repository</b> (link <a href="https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+#" target="_blank">here</a>), where it is currently hosted.</p>
<p>Two primary references support this machine learning exercise and demand special mention:</p>
<ol>
    <li>"<em><b>Taming instabilities in power grid networks by decentralized control</b></em>" (B. Schäfer, et al, The European Physical Journal, Special Topics, 2016, 225.3: 569-582), in which Dr. Schäfer (Network Dynamics, Max Planck Institute for Dynamics and Self-Organization - MPIDS, Göttingen, Germany) and his co-authors describe in detail the DSGC (Decentral Smart Grid Control) differential equation-based model to assess stability of smart grids;</li>
    <p></p>
    <li>"<em><b>Towards Concise Models of Grid Stability</b></em>" (V. Arzamasov, K. Böhm and P. Jochem, 2018 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm), Aalborg, 2018, pp. 1-6), in which Dr. Arzamasov and his co-authors explore how data-mining techniques can address DSGC model simplifications.</li>
</ol>
<p>The author is particularly thankful for Dr. Arzamasov's personal guidance and comments on the overall dataset structure.</p>
<p>Logic enhancement and code forking are welcome and encouraged provided that proper referencing to this work is made. Latest code version may be found in the author's <a href="https://github.com/pcbreviglieri" target="_blank">GitHub</a> repository. Thank you.</p>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-01-introduction" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>1. Introduction</h1>
<h2>1.1. Renewable Energy Sources and Smart Grids</h2>
<p>The ascent of renewable energy sources provides the global community with a much demanded alternative to traditional, finite and climate-unfriendly fossil fuels. However, their adoption poses a set of new paradigms, out of which two interrelated aspects deserve particular attention:</p>
<ul>
    <li>Prior to the rise of renewable energy sources, the traditional operating ecosystem involved few production entities (sources) supplying energy to consumers over unidirectional flows. With the advent of renewable options, end users (households and enterprises) now not only consume energy but have the ability to produce and supply it - hence a new term to designate them, '<b>prosumers</b>'. As a result, energy flow within distribution grids - '<b>smart grids</b>' - has become <b>bidirectional</b>;</li>
    <li>Despite the increased flexibility brought in by the introduction of renewable sources and the aforementioned emergence of 'prosumers', the management of supply and demand in a more complex generation / distribution / consumption environment and the related economic implications (particularly the decision to buy energy at a given price or not) have become even more challenging.</li>
</ul>
<p>Relevant contributions on how to tackle the requirements of such new scenario have been offered by academy and industry over the past years. Special attention has been devoted to the study of <b>smart grid stability</b>.</p>
<h2>1.2. Modeling grid stability</h2>
<p>In a smart grid, consumer demand information is collected, centrally evaluated against current supply conditions and the resulting proposed price information is sent back to customers for them to decide about usage. As the whole process is time-dependent, dynamically estimating <b>grid stability</b> becomes not only a concern but a major requirement.</p>
<p>Put simply, the objective is to understand and plan for both energy production and/or consumption disturbances and fluctuations introduced by system participants in a dynamic way, taking into consideration not only technical aspects but also how participants respond to changes in the associated economic aspects (energy price).</p>
<p>The work of researchers cited in foreword focuses on <b>Decentral Smart Grid Control</b> (DSGC) systems, a methodology strictly tied to monitoring one particular property of the grid - its frequency.</p>
<div class='row'>
    <img class="imageboxcentered" style="width: 50%" src='/smart-grid-stability/images/smart_grid_4_node_star.png' alt=''>
</div>
<h2>1.3. Addressing simplifications in the model</h2>
<p>So we have a mathematical model with which grid instability can be predicted! The need of a tool to predict grid instability would have been met, and the binary classification ("stable" versus "unstable") problem would be solved! However, the execution of this model relies on significant <b>simplifications</b>.</p>
<p>A differential equation-based model can be manipulated in several ways. One traditional approach consists in running simulations with a combination of fixed values for one subset of variables and fixed value distributions for the remaining subset. As elegantly depicted in [2], this strategy leads to <b>two primary issues</b>, referred to as the "fixed inputs issue" and the "equality issue". Please refer to [2] for a comprehensive assessment of both issues.</p>
<p>Alternative approaches have been proposed to overcome the inherent DSGC model simplifications. In particular, Dr. Arzamasov's team at the KIT suggest the use of machine learning - <b>decision trees (CART)</b> - and space-filling designs to process results from simulations with different DSGC parameter configurations.</p>
<p>In other words, machine learning is used in [2] in the following way:</p>
<ol>
    <li>A given set of input parameters (call it a 'vector') is fed into the original DSGC model;</li>
    <li>The DSGC model process this vector and returns a binary output - the grid stability for that particular set of inputs ('stable' or 'unstable' - a binary classification!);</li>
    <li>Steps 1 and 2 are executed 'n' times;</li>
    <li>A large set of vectors and the respective outputs (stability or instability) is created.</li>
</ol>
<p>In summary, the original DSGC model was run to generate a set of inputs and outputs that a 'learning machine' can process and make predictions from!</p>
<p>Per [2], accuracies of "around 80%" have been achieved with the CART-based learning machine.</p>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-02-objectives" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>2. Objectives of this machine learning exercise</h1>
<p style="text-align: justify">Considering the nature of the problem to be investigated and the dataset properties (as described in Section 3 below), two major objectives are proposed:</p>
<ol>
    <li style="text-align: justify">Pursue improvements in predictions with <b>deep learning</b> (Keras' Sequential model);</li>
    <li style="text-align: justify">Take the opportunity to assess the influence of deep learning architecture (number and size of hidden layers), number of epochs and the relevance of dataset augmentation.</li>
</ol>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-03-the-dataset" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>3. The dataset</h1>
<p>The dataset chosen for this machine learning exercise has a synthetic nature and contains results from simulations of grid stability for a reference 4-node star network, as described in 1.2.</p>
<p>The original dataset contains 10,000 observations. As the reference grid is symetric, the dataset can be augmented in 3! (3 factorial) times, or 6 times, representing a permutation of the three consumers occupying three consumer nodes. The augmented version has then <b>60,000 observations</b>. It also contains <b>12 primary predictive features</b> and two dependent variables. </p>
<p><b>Predictive features</b>:</p>
<ol>
    <li>'tau1' to 'tau4': the reaction time of each network participant, a real value within the range 0.5 to 10 ('tau1' corresponds to the supplier node, 'tau2' to 'tau4' to the consumer nodes);</li>
    <li>'p1' to 'p4': nominal power produced (positive) or consumed (negative) by each network participant, a real value within the range -2.0 to -0.5 for consumers ('p2' to 'p4'). As the total power consumed equals the total power generated, p1 (supplier node) = - (p2 + p3 + p4);</li>
    <li>'g1' to 'g4': price elasticity coefficient for each network participant, a real value within the range 0.05 to 1.00 ('g1' corresponds to the supplier node, 'g2' to 'g4' to the consumer nodes; 'g' stands for 'gamma');</li>
</ol>
<p><b>Dependent variables</b>:</p>
<ol>
    <li>'stab': the maximum real part of the characteristic differentia equation root (if positive, the system is linearly unstable; if negative, linearly stable);</li>
    <li>'stabf': a categorical (binary) label ('stable' or 'unstable').</li>
</ol>
<p>As there is a direct relationship between 'stab' and 'stabf', 'stab' will be dropped and 'stabf' will remain as the sole dependent variable.</p>
<p>As the dataset content comes from simulation exercises, there are no missing values. Also, all features are originally numerical, no feature coding is required. Such dataset properties allow for a direct jump to machine modeling without the need of data preprocessing or feature engineering.</p>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-04-initial-setup" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>4. Initial setup</h1>
<h2>4.1. Importing required libraries</h2>
<p>Along with traditional libraries imported for tensor manipulation, mathematical operations and graphics development, three scikit-learn modules (StandardScaler as a scaler, confusion_matrix as the model performance metric of choice and KFold as the cross validation engine) and two Keras deep learning objects (Sequential and Dense) are used in this exercise.</p>
<div class="boxborder">
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import KFold

from keras.models import Sequential
from keras.layers import Dense

from datetime import datetime
</code></pre>
</div>
<h2>4.2. Customized functions</h2>
<p>Functions were developed to assist with graphical analysis of specific dataset elements (features or observations) and mapping correlation. Please refer to the respective docstrings below for details. Note that all function variable names, by coding principle, start with the "f_" string, allowing for containerized processing within the function execution environment, not affecting global variables.</p>
<div class="boxborder">
<pre><code class="language-python">def assessment(f_data, f_y_feature, f_x_feature, f_index=-1):
    &quot;&quot;&quot;
    Develops and displays a histogram and a scatter plot for a dependent / independent variable pair from
    a dataframe and, optionally, highlights a specific observation on the plot in a different color (red).
    
    Also optionally, if an independent feature is not informed, the scatterplot is not displayed.
    
    Keyword arguments:
    
    f_data      Tensor containing the dependent / independent variable pair.
                Pandas dataframe
    f_y_feature Dependent variable designation.
                String
    f_x_feature Independent variable designation.
                String
    f_index     If greater or equal to zero, the observation denoted by f_index will be plotted in red.
                Integer
    &quot;&quot;&quot;
    for f_row in f_data:
        if f_index &amp;gt;= 0:
            f_color = np.where(f_data[f_row].index == f_index,'r','g')
            f_hue = None
        else:
            f_color = 'b'
            f_hue = None
    
    f_fig, f_a = plt.subplots(1, 2, figsize=(16,4))
    
    f_chart1 = sns.distplot(f_data[f_x_feature], ax=f_a[0], kde=False, color='g')
    f_chart1.set_xlabel(f_x_feature,fontsize=10)
    
    if f_index &amp;gt;= 0:
        f_chart2 = plt.scatter(f_data[f_x_feature], f_data[f_y_feature], c=f_color, edgecolors='w')
        f_chart2 = plt.xlabel(f_x_feature, fontsize=10)
        f_chart2 = plt.ylabel(f_y_feature, fontsize=10)
    else:
        f_chart2 = sns.scatterplot(x=f_x_feature, y=f_y_feature, data=f_data, hue=f_hue, legend=False)
        f_chart2.set_xlabel(f_x_feature,fontsize=10)
        f_chart2.set_ylabel(f_y_feature,fontsize=10)

    plt.show()

    
def correlation_map(f_data, f_feature, f_number):
    &quot;&quot;&quot;
    Develops and displays a heatmap plot referenced to a primary feature of a dataframe, highlighting
    the correlation among the 'n' mostly correlated features of the dataframe.
    
    Keyword arguments:
    
    f_data      Tensor containing all relevant features, including the primary.
                Pandas dataframe
    f_feature   The primary feature.
                String
    f_number    The number of features most correlated to the primary feature.
                Integer
    &quot;&quot;&quot;
    f_most_correlated = f_data.corr().nlargest(f_number,f_feature)[f_feature].index
    f_correlation = f_data[f_most_correlated].corr()
    
    f_mask = np.zeros_like(f_correlation)
    f_mask[np.triu_indices_from(f_mask)] = True
    with sns.axes_style(&quot;white&quot;):
        f_fig, f_ax = plt.subplots(figsize=(20, 10))
        sns.heatmap(f_correlation, mask=f_mask, vmin=-1, vmax=1, square=True,
                    center=0, annot=True, annot_kws={&quot;size&quot;: 8}, cmap=&quot;PRGn&quot;)
    plt.show()
</code></pre>
</div>
<h2>4.3. Importing required datasets into dataframes</h2>
<p>The augmented dataset (60,000 observations) is imported. The dependent variable is map encoded ('stable' replaced with 1, 'unstable' with 0). At last, the 60,000 observations are shuffled.</p>
<div class="boxborder">
<pre><code class="language-python">start_time = datetime.now()

data = pd.read_csv('smart_grid_stability_augmented.csv')

map1 = {'unstable': 0, 'stable': 1}
data['stabf'] = data['stabf'].replace(map1)

data = data.sample(frac=1)
</code></pre>
</div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-05-exploratory-data-analysis" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>5. Exploratory data analysis</h1>
<p>A glimpse at the dataset structure confirms observation shuffling and the close relationship between the two original dependent variables 'stab' and 'stabf'.</p>
<h2>5.1. Feature assessment</h2>
<p>Distribution patterns and the relationship with the 'stab' dependent variable is charted for each of the 12 dataset features.</p>
<p>As this data comes from simulations with predetermined fixed ranges for all features, as described in Section 3, distributions are pretty much uniform across the board, with the exception of 'p1' (absolute sum of 'p2', 'p3' and 'p4'), which follows a normal distribution (as expected) with a very small skew factor of -0.013.</p>
<div class="boxborder">
<pre><code class="language-python">for column in data.columns:
    assessment(data, 'stab', column, -1)
</code></pre>
</div>
<p>INSERT SLIDER OR GALLERY</p>
<div class="boxborder">
<pre><code class="language-python">data.p1.skew()
</code></pre>
</div>
<p class="codeoutput">-0.012688423269883486</p>
<p>The proportion of observations related to 'unstable' and 'stable' scenarios is mapped.</p>
<div class="boxborder">
<pre><code class="language-python">print(f'Split of &quot;unstable&quot; (0) and &quot;stable&quot; (1) observations in the original dataset:')
print(data['stabf'].value_counts(normalize=True))
</code></pre>
</div>
<p class="codeoutput">Split of "unstable" (0) and "stable" (1) observations in the original dataset:<br/>
0 0.638<br/>
1 0.362<br/>
Name: stabf, dtype: float64</p>
<h2>5.2. Correlation</h2>
<p>It is important to verify the correlation between each numerical feature and the dependent variable, as well as correlation among numerical features leading to potential undesired colinearity. The heatmap below provides an overview of correlation between the dependent variable ('stabf') and the 12 numerical features. Note that also the alternative dependent variable ('stab') has been included just to give an idea of how correlated it is with 'stabf'. Such correlation is significant (-0.83), as it should be, which reinforces the decision to drop it, anticipated in Section 3. Also, correlation between 'p1' and its components 'p2', 'p3' and 'p4' is above average, as expected, but not as high o justify any removal. </p>
<div class="boxborder">
<pre><code class="language-python">correlation_map(data, 'stabf', 14)
</code></pre>
</div>
<div class='row'>
    <img class="imageboxcentered" style="width: 50%" src='/smart-grid-stability/images/correl.png' alt=''>
</div>
<h2>5.3. Segregating train and test sets</h2>
<p>As anticipated, the features dataset will contain all 12 original predictive features, while the label dataset will contain only 'stabf' ('stab' is dropped here).</p>
<p>In addition, as the dataset has already been shuffled, the training set will receive the first 54,000 observations, while the testing set will accommodate the last 6,000.</p>
<p>Even considering that the dataset is large enough and well behaved, the percentage of 'stable' and 'unstable' observations is computed for both training and testing sets, just to make sure that the original dataset distribution is maintained after the split - which proved to be the case.</p>
<p>After splitting, Pandas dataframes and series are transformed into Numpy arrays for the remainder of the exercise.</p>
<div class="boxborder">
<pre><code class="language-python">X = data.iloc[:, :12]
y = data.iloc[:, 13]

X_training = X.iloc[:54000, :]
y_training = y.iloc[:54000]

X_testing = X.iloc[54000:, :]
y_testing = y.iloc[54000:]

ratio_training = y_training.value_counts(normalize=True)
ratio_testing = y_testing.value_counts(normalize=True)
ratio_training, ratio_testing
</code></pre>
</div>
<p class="codeoutput">(0 0.638407<br/>
1 0.361593<br/>
Name: stabf, dtype: float64,<br/>
0 0.634333<br/>
1 0.365667<br/>
Name: stabf, dtype: float64)</p>
<div class="boxborder">
<pre><code class="language-python">X_training = X_training.values
y_training = y_training.values

X_testing = X_testing.values
y_testing = y_testing.values
</code></pre>
</div>
<h2>5.4. Feature scaling</h2>
<p>In preparation for machine learning, scaling is performed based on (fitted to) the training set and applied (with the 'transform' method) to both training and testing sets.</p>
<div class="boxborder">
<pre><code class="language-python">scaler = StandardScaler()
X_training = scaler.fit_transform(X_training)
X_testing = scaler.transform(X_testing)
</code></pre>
</div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-06-deep-learning" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>6. Deep Learning</h1>
<h2>6.1. Model definition</h2>
<p>The artificial neural network (ANN) architecture depicted below is the optimal one evaluated in this study. It reflects an sequential structure with:</p>
<ul>
    <li>one input layer (12 input nodes);</li>
    <li>three hidden layers (24, 24 and 12 nodes, respectively);</li>
    <li>one single-node output layer.</li>
</ul>
<p>Alternative architectures were evaluated with variations of the code below. Their performance will be discussed in Section 7.</p>
<p>As features are numerical real numbers within ranges, the choice of 'relu' as the activation function for hidden layers seems straightforward. Similarly, as this is a logistic classification exercise, where the output is binary ('0' for 'unstable', '1' for 'stable', following the map coding used in Section 4.3), the choice of 'sigmoid' as activation for the output layers seems obvious.</p>
<p>Compilation with 'adam' as optimizer and 'binary_crossentropy' as the loss function follow the same logic. The fitting performance will be assessed using 'accuracy' as the metric of choice.</p>
<div class='row'>
    <img class="imageboxcentered" style="width: 50%" src='/smart-grid-stability/images/ann.png' alt=''>
</div>
<div class="boxborder">
<pre><code class="language-python"># ANN initialization
classifier = Sequential()

# Input layer and first hidden layer
classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))

# Second hidden layer
classifier.add(Dense(units = 24, kernel_initializer = 'uniform', activation = 'relu'))

# Third hidden layer
classifier.add(Dense(units = 12, kernel_initializer = 'uniform', activation = 'relu'))

# Single-node output layer
classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))

# ANN compilation
classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
</code></pre>
</div>
<h2>6.2. Model fitting</h2>
<p>Even considering that data is well behaved and in general uniformly distributed, a cross-validation based fitting is proposed. KFold is the cross-validation engine selected, and 10 different validation sets will be utilized.</p>
<div class="boxborder">
<pre><code class="language-python">cross_val_round = 1

for train_index, val_index in KFold(10, shuffle=True, random_state=10).split(X_training):
    x_train, x_val = X_training[train_index], X_training[val_index]
    y_train ,y_val = y_training[train_index], y_training[val_index]
    classifier.fit(x_train, y_train, epochs=50)
    print(f'\nModel evaluation - Round {cross_val_round}: {classifier.evaluate(x_val, y_val)}\n')
    cross_val_round += 1
</code></pre>
</div>
<p class="codeoutput">Epoch 1/50<br/>
48600/48600 [==============================] - 8s 159us/step - loss: 0.2928 - accuracy: 0.8658<br/>
Epoch 2/50<br/>
48600/48600 [==============================] - 6s 132us/step - loss: 0.1645 - accuracy: 0.9290<br/>
......<br/>
Epoch 50/50<br/>
48600/48600 [==============================] - 8s 155us/step - loss: 0.0812 - accuracy: 0.9661<br/>
5400/5400 [==============================] - 0s 68us/step<br/>
Model evaluation - Round 1: [0.08852494491195237, 0.9622222185134888]<br/>
......<br/>
Epoch 50/50<br/>
48600/48600 [==============================] - 6s 133us/step - loss: 0.0295 - accuracy: 0.9877<br/>
5400/5400 [==============================] - 0s 41us/step<br/>
Model evaluation - Round 10: [0.037231814745755404, 0.9851852059364319]</p>
<h2>6.3. Predicting smart grid stability</h2>
<p>After fitting the model to the training set, it is time to extract predictions for the testing set and segregate those above the 'threshold' of 0.5 ('unstable' cases below the threshold, 'stable' cases above it).</p>
<div class="boxborder">
<pre><code class="language-python">y_pred = classifier.predict(X_testing)
y_pred[y_pred &amp;lt;= 0.5] = 0 y_pred[y_pred &amp;gt; 0.5] = 1
</code></pre>
</div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-07-results" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>7. Results</h1>
<h2>7.1. Classification performance - Confusion matrix</h2>
<p>The segregation described in Section 6.3 allows for the construction of a confusion matrix.</p>
<div class="boxborder">
<pre><code class="language-python">print(confusion_matrix(y_testing, y_pred))
</code></pre>
</div>
<p class="codeoutput">[[3712 71]<br/>
[ 60 2157]]</p>
<div class="boxborder">
<pre><code class="language-python"># Confusion Matrix

cm = pd.DataFrame(data=confusion_matrix(y_testing, y_pred, labels=[0, 1]),
                  index=[&quot;Actual Unstable&quot;, &quot;Actual Stable&quot;],
                  columns=[&quot;Predicted Unstable&quot;, &quot;Predicted Stable&quot;])
cm
</code></pre>
</div>
<table style="width: 40%; margin-top: 0.5em;">
    <tbody class="codeoutput">
        <tr style="width: 50%;">
            <td style="width: 34%; text-align: center; border: 0;""></td>
            <td style="width: 33%; text-align: center; border: 0;"">Predicted Unstable</td>
            <td style="width: 33%; text-align: center; border: 0;"">Predicted Stable</td>
        </tr>
        <tr style="width: 50%;">
            <td style="width: 34%; text-align: center; border: 0;"">Actual Unstable</td>
            <td style="width: 33%; text-align: center; border: 0;"">3712</td>
            <td style="width: 33%; text-align: center; border: 0;"">71</td>
        </tr>
        <tr style="width: 50%;">
            <td style="width: 34%; text-align: center; border: 0;"">Actual Stable</td>
            <td style="width: 33%; text-align: center; border: 0;"">60</td>
            <td style="width: 33%; text-align: center; border: 0;"">2157</td>
        </tr>
    </tbody>
</table>
<p>Analysis shows that a total of 3,712 'unstable' predictions and 2,157 'stable' predictions were correct, leading to an overall <b>accuracy of 97.82%</b> on the testing set.</p>
<h2>7.2. Alternative configurations</h2>
<p>The architecture and the hyperparameters selected above led to the best prediction performance on the test set.</p>
<p>In addition, several other combinations were evaluated for both the original dataset with 1,000 observations and the augmented dataset with 6,000 observations. It is important to emphasize that in this comparative assessment <b>no shuffling</b> of any type, at any part of the exercise, was performed, so that the very same testing set was exposed to model after fitting for performance assessment.</p>
<p>The table below summarizes obtained results:</p>
<div class='row'>
    <img class="imageboxcentered" style="width: 80%" src='/smart-grid-stability/images/alternative_configurations.png' alt=''>
</div>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  
    
    
  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  <section id="section-08-discussion-and-final-remarks" class="home-section wg-blank   " style="padding: 0 0 0 0;" >
    <div class="container">
      


<div class="row">
  
    <div class="col-lg-12">
      
      
      <h1>8. Discussion and final remarks</h1>
<p>Specific aspects of this deep learning exercise demand special attention:</p>
<ol>
    <li>Deep learning proved to be an outstanding prediction tool for this particular application. Even considering that the dataset is well behaved and needed no significant preprocessing, the <b>high accuracies</b> obtained on the testing set confirm that a deep learning model may be safely considered. It would though be up to a smart grid operator to confirm if the accuracy level obtained with deep learning would suffice in practical terms (live network);</li>
    <li>As expected, more complex ANN architectures <b>performed better</b> than simpler ones;</li>
    <li>An <b>increased number of epochs</b> considered during fitting also plays a major role. It is evident that the more the model is exposed to the training set, the better the prediction accuracy;</li>
    <li>From a machine learning exercise perspective, the use of an <b>augmented dataset</b> with 6,000 observations contributed significantly to better results;</li>
	<li>It must be noted that input parameters utilized in the original DSGC simulations fall within predetermined ranges. As a follow-up step in the validation of this learning machine, it would be interesting to assess its performance using a new test set with observations obtained from simulations with input parameter values residing in other alternative ranges.</li>
</ol>
<div class="boxborder">
<pre><code class="language-python">end_time = datetime.now()

print('\nStart time', start_time)
print('End time', end_time)
print('Time elapsed', end_time - start_time)
</code></pre>
</div>

    </div>
  
</div>

    </div>
  </section>



      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js" integrity="sha512-7t8APmYpzEsZP7CYoA7RfMPV9Bb+PJHa9x2WiUnDXZx3XHveuyWUtvNOexhkierl5flZ3tr92dP1mMS+SGlD+A==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/python.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.3b2b658c61ebd725bd5fc606c89fe44c.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms of Service</a>
    
  </p>
  

  <p class="powered-by">
    © 2020 Paulo Breviglieri - All rights reserved
  </p>

</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
